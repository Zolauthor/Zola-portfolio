{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bank client behavior prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About dataset\n",
    "\n",
    "- For this analysis there are two files in the `data` folder `credit_record.csv` and `application_record.csv` where bank clients are related by the `ID` column.\n",
    "\n",
    "- In `application_record.csv` we have the following variables\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number      |         |\n",
    "| AMT_INCOME   | Annual income  |  |\n",
    "| NAME_INCOME_TYPE   | Income Source |  |\n",
    "| NAME_EDUCATION_TYPE   | Level of Education  |  |\n",
    "| CODE_GENDER   | Applicant's Gender   |  |\n",
    "| FLAG_OWN_CAR | Car Ownership |  | \n",
    "| CNT_CHILDREN | Number of Children | |\n",
    "| FLAG_OWN_REALTY | Real Estate Ownership | | \n",
    "| NAME_FAMILY_STATUS | Relationship Status | | \n",
    "| NAME_HOUSING_TYPE | Housing Type | | \n",
    "| DAYS_BIRTH | No. of Days | Count backwards from current day (0), -1 means yesterday\n",
    "| DAYS_EMPLOYED | No. of Days | Count backwards from current day (0). If positive, it means the person is currently unemployed.\n",
    "| FLAG_MOBIL | Mobile Phone Ownership | | \n",
    "| FLAG_WORK_PHONE | Work Phone Ownership | | \n",
    "| FLAG_PHONE | Landline Phone Ownership | | \n",
    "| FLAG_EMAIL | Landline Phone Ownership | | \n",
    "| OCCUPATION_TYPE | Occupation | | \n",
    "| CNT_FAM_MEMBERS | Count of Family Members | |\n",
    "\n",
    "\n",
    "\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number | |\n",
    "| MONTHS_BALANCE | Number of months in the past from now when STATUS is measured | 0 = current month, -1 = last month, -2 = two months ago, etc.|\n",
    "| STATUS | Number of days a payment is past due | 0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Part 1. Reading, Summarising and Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part involved importing the datasets into Dataframes and determining the number of rows and unique bank clients in each. I then merged the two datasets on a common ID column, applying an inner join to focus only on matching records, creating a consolidated DataFrame.\n",
    "\n",
    "This allowed me to explore the merged data, analyze the number of rows and unique clients, and investigate differences in multiple rows associated with the same ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 438445 rows in df_application\n",
      "There are 1047185 rows in df_credit\n",
      "There are 438398 unique clients in df_application\n",
      "There are 45924 unique clients in df_credit\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_application = pd.read_csv('data/application_record.csv')\n",
    "df_credit = pd.read_csv('data/credit_record.csv')\n",
    "\n",
    "#2. Printing number of rows os dataframes:\n",
    "print(f'There are {df_application.shape[0]} rows in df_application')\n",
    "print(f'There are {df_credit.shape[0]} rows in df_credit')\n",
    "\n",
    "#3. Printing number of unique clients:\n",
    "print(f'There are {df_application['ID'].nunique()} unique clients in df_application')\n",
    "print(f'There are {df_credit['ID'].nunique()} unique clients in df_credit')\n",
    "\n",
    "#4. Merging two dataframes into one, using ID columns:\n",
    "df = pd.merge(df_application, df_credit, on='ID', how='inner')\n",
    "\n",
    "#5. Checking number of rows and unique clients in new dataframe:\n",
    "#df.shape\n",
    "#df['ID'].nunique()\n",
    "\n",
    "#6. Checking for the duplicated rows difference: \n",
    "#duplicates = df.duplicated(subset=['ID'])\n",
    "#print(df[duplicates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 outcome:\n",
    "1. Number of rows in dataframes:\n",
    "    - There are **438,445** rows in `df_application` dataframe.\n",
    "    - There are has **1,047,185** rows in `df_credit` dataframe.\n",
    "2. Number of unique clients in both dataframes:\n",
    "    - There are **438,398** unique clients in `df_application` dataframe.\n",
    "    - There are **45,924** unique clients in `df_credit` dataframe.\n",
    "3. `df` dataframe details after merge:\n",
    "    - There are **776,325** rows in `df` dataframe after the merge.\n",
    "    - There are **36,396** unique clients in `df` dataframe after the merge.\n",
    "4. Explanation on multiple rows for each ID in `df` dataframe:\n",
    "    - One user can have multiple record of payment status and monthly balance over time.\n",
    "    - Over time informations like employment status, occupation, income, family status can change.\n",
    "    - Therefore, multiple IDs are different as they represent different records of one client. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Part 2. Data Wrangling and Feature Engineering for Client Overdue Analysis\n",
    "After merging these datasets based on a common ID column, I performed a series of data wrangling tasks to identify clients with overdue payments in the last 12 months. This involved mapping the STATUS column to indicate whether a client had past-due payments and filtering the data accordingly. I utilized NumPy to extract unique client IDs with overdue statuses and created a new Dataframe containing these clients, ensuring duplicates were removed and missing values handled efficiently.\n",
    "\n",
    "I then appended additional rows to balance the dataset to a required size, while marking each client with an appropriate target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1737 rows in df_final\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#1. Changing STATUS with manual mapping:\n",
    "mapping = {'C': 0, 'X': 0, '0': 0,'1': 1, '2': 1, '3': 1, '4': 1, '5': 1}\n",
    "df['STATUS'] = df['STATUS'].map(mapping)\n",
    "\n",
    "#2. Filtering the df where STATUS is 1 during last 12 months:\n",
    "last_year_status = df.loc[(df['STATUS'] == 1) & (df['MONTHS_BALANCE'] >= -11)]\n",
    "\n",
    "#Converting the unique IDs to a numpy array\n",
    "list_of_past_due = np.array(last_year_status['ID'].unique())\n",
    "\n",
    "#3. Creating new dataframe with IDs in list_of_past_due:\n",
    "df_final = df.loc[df['ID'].isin(list_of_past_due)]\n",
    "\n",
    "# Deleting duplicated rows, only keeping first occurance: \n",
    "df_final = df_final.drop_duplicates(subset=['ID'], keep='first')\n",
    "\n",
    "print(f'There are {df_final.shape[0]} rows in df_final')\n",
    "\n",
    "#4. Adding new column for all rows in df_final:\n",
    "df_final['y'] = 1\n",
    "\n",
    "#5. Filtering rows with unique ID that are not in list_of_past_due:\n",
    "df_add = df[~df['ID'].isin(list_of_past_due)].drop_duplicates(subset=['ID'], keep='first')\n",
    "\n",
    "# Number of rows needed:\n",
    "rows = 4500 - df_final.shape[0]\n",
    "\n",
    "# Selecting only rows that required:\n",
    "df_required = df_add.iloc[:rows]\n",
    "\n",
    "# Adding rows to df_final:\n",
    "df_final = pd.concat([df_final, df_required], ignore_index=True)\n",
    "\n",
    "#6. Filling missing values with zeros:\n",
    "df_final['y'] = df_final['y'].fillna(0)\n",
    "\n",
    "# Removing the 'STATUS' and 'MONTHS_BALANCE' columns from df_final\n",
    "df_final.drop(columns=['STATUS', 'MONTHS_BALANCE'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Part 3. Data Cleaning and Variable Classification for Final Dataset Preparation\n",
    "In this part, I focused on refining the dataset df_final by first removing the ID column, as it was no longer necessary for further analysis, and then resetting the index to ensure a clean and continuous structure. \n",
    "\n",
    "Next, I used pandas functions to check for missing values within the dataset. This process involved calculating the number of missing values in each column and sorting the results to assess which features required further attention. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Deleting ID column from df_final:\n",
    "df_final.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "# Resetting index of df_final:\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#3. Finding missing values: \n",
    "#df_final.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 markdown:\n",
    "1. There are 5 numeric and 12 nominal and 1 ordinal variables in `df_final`. Names of variables of each types are shown in following table:\n",
    "   \n",
    "|Variable type|Numbers of features|Features' list|\n",
    "| --- | --- | --- |\n",
    "|Numeric:|5|CNT_CHILDREN, AMT_INCOME, DAYS_BIRTH, DAYS_EMPLOYED, CNT_FAM_MEMBERS|\n",
    "|Ordinal:|1| NAME_EDUCATION_TYPE |\n",
    "|Nominal:|12|CODE_GENDER, FLAG_OWN_CAR, FLAG_OWN_REALTY, NAME_INCOME_TYPE, NAME_FAMILY_STATUS, NAME_HOUSING_TYPE, FLAG_MOBIL, FLAG_WORK_PHONE, FLAG_PHONE, FLAG_EMAIL, OCCUPATION_TYPE, y|\n",
    "\n",
    "2. Using `isnull().sum().sort_values()` function I sorted which particular variables have missing values. This method is more suitable because it helps us exclude features which does not have missing values and identify and focus on features with missing values. Total number of missing values of each variables are shown in following table: \n",
    "   \n",
    "|Feature name|Variable type|Number of missing values|\n",
    "| --- | --- | --- |\n",
    "|CNT_CHILDREN|Numeric|74|\n",
    "|OCCUPATION_TYPE|Nominal|1354|\n",
    "|NAME_EDUCATION_TYPE|Ordinal|1831|\n",
    "\n",
    "From the table we can see that we have 3 features with missing values: \n",
    "- CNT_CHILDREN is numeric variable as it is number if children we can't use mean, therefore will impute missing values with median.\n",
    "- OCCUPATION_TYPE is nominal feature, thus will impute missing values with mode.\n",
    "- NAME_EDUCATION_TYPE is ordinal feature, thus will mpute missing values with mode.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Part 4. Imputing missing values and dealing with categorical features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part handled missing values in a dataset by applying different imputation techniques based on the nature of the variables. For numerical data, I used the median to fill in missing values, ensuring robustness against outliers. For nominal data, I applied the mode to maintain the most common category. Similarly, for ordinal data in NAME_EDUCATION_TYPE, I used the mode to preserve the order and frequency of the values. This careful imputation process ensured that the dataset was complete and ready for accurate analysis, while maintaining the integrity of each variable type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values in CNT_CHILDREN with the mean, since it is numerical data:\n",
    "df_final['CNT_CHILDREN'].fillna(df_final['CNT_CHILDREN'].median(), inplace=True)\n",
    "\n",
    "# Imputing missing values in OCCUPATION_TYPE with the mode, since it is nominal data:\n",
    "df_final['OCCUPATION_TYPE'].fillna(df_final['OCCUPATION_TYPE'].mode()[0], inplace=True)\n",
    "\n",
    "# Imputing missing values in NAME_EDUCATION_TYPE with the mode, since it is ordinal data:\n",
    "df_final['NAME_EDUCATION_TYPE'].fillna(df_final['NAME_EDUCATION_TYPE'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Part 5. Ordinal Variable Conversion for Educational Levels\n",
    "\n",
    "Converting the values in `NAME_EDUCATION_TYPE` as follows\n",
    "- Lower secondary -> 1\n",
    "- Secondary / secondary special -> 2\n",
    "- Incomplete higher -> 3\n",
    "- Higher education -> 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mapping to convert, since it is ordinal data\n",
    "edu_mapping = {'Lower secondary': 1, 'Secondary / secondary special': 2, 'Incomplete higher': 3, 'Higher education': 4}\n",
    "df_final['NAME_EDUCATION_TYPE'] = df_final['NAME_EDUCATION_TYPE'].replace(edu_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Part 5. One-Hot Encoding of Nominal Features\n",
    "\n",
    "In this step, I applied one-hot encoding to the nominal features in the df_final Dataframe, converting them into dummy variables to make the data suitable for machine learning models. First, I identified the nominal features, which were originally stored as strings, and used the get_dummies() function to create binary variables for each category in these features. To avoid multicollinearity, I set the drop_first=True parameter, which removed the first column from each set of dummy variables. This ensures that the encoded variables are not redundant. After creating the dummy variables, I dropped the original nominal columns from df_final and added the newly created dummy variables back into the DataFrame. This process transformed the categorical data into a numerical format, making it ready for analysis and machine learning, while ensuring efficient and accurate encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting nominal features:\n",
    "nominal_str = df_final.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Creating dummy variables:\n",
    "nominal_hot = pd.get_dummies(df_final[nominal_str], dtype=int, drop_first=True)\n",
    "\n",
    "# Dropping the original nominal columns from df_final\n",
    "df_final = df_final.drop(columns=nominal_str)\n",
    "\n",
    "# Joining the dummy variables back to df_final\n",
    "df_final = df_final.join(nominal_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Part 6. Data standardization and training\n",
    "In this part, I prepared the dataset for machine learning by splitting it into training and testing sets and standardizing the feature values. First, I separated the target variable y from the feature matrix X. Using train_test_split from the sklearn.model_selection library, I split the data into 75% training data and 25% testing data, ensuring the target variable y was stratified to maintain the same class proportions in both sets.\n",
    "\n",
    "After splitting, I standardized the feature values using StandardScaler. This scaling technique ensures that all features have a mean of 0 and a standard deviation of 1, which is essential for many machine learning algorithms to perform optimally. The scaler was fitted on the training data and then applied to both the training and test sets to avoid data leakage. This process ensures that the model is trained on normalized data, improving its efficiency and performance during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_final['y'].astype(int).values\n",
    "X = df_final.drop(columns=['y']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Splitting the data into 75% train and 25% test datasets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Part 7. Logistic Regression and Random Forest Classifiers and Accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the project, I trained two machine learning models—a Logistic Regression classifier and a Random Forest classifier—on standardized data to evaluate their performance. First, I trained a Logistic Regression model using the training data, with random_state set to 10 for reproducibility. After fitting the model, I calculated the accuracy for both the training and test datasets, which provided insight into how well the model generalizes to unseen data.\n",
    "\n",
    "Next, I trained a Random Forest classifier, also with random_state set to 10, to compare its performance with the Logistic Regression model. I similarly calculated and printed the training and test accuracies to evaluate the model's fit and ability to predict on new data.\n",
    "\n",
    "This comparison between two different models showcases my ability to implement, train, and evaluate multiple machine learning algorithms, leveraging accuracy metrics to assess their performance and draw insights on model effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression training accuracy: 0.660\n",
      "Logistic regression test accuracy: 0.660\n",
      "Random forest training accuracy: 0.977\n",
      "Random forest test accuracy: 0.888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Logistic Regression model:\n",
    "lr = LogisticRegression(random_state=10)\n",
    "\n",
    "# Training the model on the training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Computing accuracy:\n",
    "train_lr = accuracy_score(y_train, lr.predict(X_train))\n",
    "test_lr = accuracy_score(y_test, lr.predict(X_test))\n",
    "\n",
    "print(f'Logistic regression training accuracy: {train_lr:.3f}')\n",
    "print(f'Logistic regression test accuracy: {test_lr:.3f}')\n",
    "\n",
    "#Random forest model:\n",
    "rf = RandomForestClassifier(random_state=10)\n",
    "\n",
    "# Training the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Computing accuracy:\n",
    "train_rf = accuracy_score(y_train, rf.predict(X_train))\n",
    "test_rf = accuracy_score(y_test, rf.predict(X_test))\n",
    "\n",
    "print(f'Random forest training accuracy: {train_rf:.3f}')\n",
    "print(f'Random forest test accuracy: {test_rf:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 7 markdown: \n",
    "1. Training and test accuracy comparison:\n",
    "- **Logistic regression** : Training accuracy(0.660) and test accuracy(0.660) of logistic regression model are same. This means that model is not overfitted it performs same on both training and test data.\n",
    "- **Random forest** : Training accuracy(0.977) is higher than test accuracy(0.888). This means that model is slightly overfitted, it performs well on training data but its performance drops on unseen data. But since the test accuracy rate is 88.8%% it shows sufficient generalization. \n",
    "  \n",
    "2. Classifier performance comparison:\n",
    "Although logistic regression shows consistency throughout training and test data, random forest model delivers higher test accuracy rate(88.8%). This shows that random forest will capture more pattern, leading to better forecasting rather than logistic regression.\n",
    "\n",
    "3. Since random forest significantly outperforms logistic regression, this suggests the presence of nonlinearities in the dataset. The lower performance of logistic regression can likely be attributed to its assumption of linearity, whereas random forest's ability to model nonlinearity resulted in better performance. This implies that the relationships between the features and the dependent variable in this dataset are not linear, and random forest appears to be preffered choise to modeling these complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
